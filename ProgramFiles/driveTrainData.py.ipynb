{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7724de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fileWriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23380/1498813298.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \"\"\"\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#from vehicleSerial import *\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfileWriter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \"\"\"\n\u001b[0;32m     26\u001b[0m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'drive training data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fileWriter'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import skimage\n",
    "from skimage import morphology\n",
    "import datetime\n",
    "import json\n",
    "#import freenect  #-Take this out for now as its the module for the xbox kinect and we are using webcam\n",
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import network - this module is to connect to wlan.  We may not need it\n",
    "from optimizer import restore_snapshot\n",
    "from datasets import cityscapes\n",
    "from config import assert_and_infer_cfg\n",
    "\n",
    "from vehicleSerial import *\n",
    "from fileWriter import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description='drive training data')\n",
    "parser.add_argument('--savevideo', type=str, default='', help='save incoming video')\n",
    "parser.add_argument('--snapshot', type=str, default='./pretrained_models/cityscapes_cv0_seresnext50_nosdcaug.pth', help='pre-trained checkpoint')\n",
    "parser.add_argument('--arch', type=str, default='network.deepv3.DeepSRNX50V3PlusD_m1', help='network architecture used for inference')\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "assert_and_infer_cfg(args, train_mode=False)\n",
    "cudnn.benchmark = False\n",
    "beginTime = datetime.date\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "setupWriter(False)\n",
    "\n",
    "print('starting segmentation network....')\n",
    "\n",
    "# get net\n",
    "args.dataset_cls = cityscapes\n",
    "net = network.get_net(args, criterion=None)\n",
    "net = torch.nn.DataParallel(net).cuda()\n",
    "print('Net built.')\n",
    "net, _ = restore_snapshot(net, optimizer=None, snapshot=args.snapshot, restore_optimizer_bool=False)\n",
    "net.eval()\n",
    "print('Net restored.')\n",
    "\n",
    "# get data\n",
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(*mean_std)])\n",
    "\n",
    "#cap = cv2.VideoCapture(args.video)\n",
    "\n",
    "framecount = 0\n",
    "\n",
    "prevFrame = None\n",
    "\n",
    "\n",
    "def draw_user_angle(pilot_angle, pilot_throttle, img):\n",
    "    '''\n",
    "    query the model for it's prediction, draw the predictions\n",
    "    as a blue line on the image\n",
    "\n",
    "    Taken from https://github.com/autorope/donkeycar/blob/bd854d3de6b109d9ae711dba271305f4b4c0c55d/donkeycar/management/makemovie.py\n",
    "    '''\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    length = height\n",
    "    a2 = pilot_angle * 45.0\n",
    "    l2 = pilot_throttle * length\n",
    "\n",
    "    mid = width // 2 - 1\n",
    "\n",
    "    p2 = tuple((mid + 2, height - 1))\n",
    "    p22 = tuple((int(p2[0] + l2 * math.cos((a2 + 270.0) * (math.pi / 180.0))),\n",
    "                    int(p2[1] + l2 * math.sin((a2 + 270.0) * (math.pi / 180.0)))))\n",
    "\n",
    "    # user is green, pilot is blue\n",
    "    cv2.line(img, p2, p22, (0, 0, 255), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def filterConnectedComponents(pred):\n",
    "    label_img, cc_num = ndimage.label(pred)\n",
    "    sizes = ndimage.sum(pred, label_img, range(cc_num+1))\n",
    "    #print(sizes)\n",
    "    mask_size = sizes < 50\n",
    "    remove_pixel = mask_size[label_img]\n",
    "    label_img[remove_pixel] = 0\n",
    "    return label_img\n",
    "\n",
    "def map(x, in_min, in_max, out_min, out_max):\n",
    "    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "\n",
    "\"\"\"\n",
    "#Take this out for now as its using freenect which is the XBOX kinect.  If not working, put back in and use kinect or cv2.VideoCapture() with webcam\n",
    "\n",
    "def get_video():\n",
    "    array,_ = freenect.sync_get_video()\n",
    "    array = cv2.cvtColor(array,cv2.COLOR_RGB2BGR)\n",
    "    return array\n",
    "\"\"\"\n",
    "#connect to autonomous vehicle\n",
    "connectionResult = connect('/dev/ttyUSB0')\n",
    "\n",
    "while connectionResult != \"success\":\n",
    "    print(\"arduino failed to connect but trying again...\")\n",
    "    connectionResult = connect('/dev/ttyUSB0')\n",
    "\n",
    "print(\"arduino connected!\")\n",
    "\n",
    "if args.savevideo:\n",
    "    out = cv2.VideoWriter(\"OcciRunBad\" + \".avi\", cv2.VideoWriter_fourcc('M','J','P','G'),10,(512,256))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    #img = get_video()\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img = cv2.resize(img,(512,256))\n",
    "    cv2.imshow(\"IN\", img)\n",
    "    \n",
    "    if args.savevideo:\n",
    "        out.write(img)\n",
    "\n",
    "    if framecount % 5 == 0:   \n",
    "        #reading steering and throttle value as fast as possible to make sure there is no delay\n",
    "        \n",
    "        steeringValue, throttleValue = readValue()\n",
    "\n",
    "        if steeringValue != -1 or steeringValue != 1:\n",
    "            img2 = img\n",
    "            img_tensor = img_transform(img2)\n",
    "\n",
    "            # predict\n",
    "            with torch.no_grad():\n",
    "                img2 = img_tensor.unsqueeze(0).cuda().cpu()\n",
    "                pred = net(img2)\n",
    "\n",
    "            pred = pred.cpu().numpy().squeeze()\n",
    "            pred = np.argmax(pred, axis=0)\n",
    " \n",
    "            colorized = args.dataset_cls.colorize_mask(pred)\n",
    "            img = np.array(colorized.convert('RGB'))\n",
    "            kernel = np.ones((15,15),np.uint8)\n",
    "            img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "            median = cv2.medianBlur(img, 17)\n",
    "\n",
    "            #write data to disk for training\n",
    "            writeTrainData(steeringValue,throttleValue,median,int(framecount/5))\n",
    "\n",
    "            #endTime = datetime.datetime.now()\n",
    "\n",
    "            #elapsedTime = endTime - beginTime\n",
    "            #if(elapsedTime.microseconds > 0.0):\n",
    "            #    fps = round(1 / (elapsedTime.microseconds * 10**-6),2) \n",
    "                #cv2.putText(img,\"fps: \" + str(fps),(10,90), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),4,cv2.LINE_AA)\n",
    "\n",
    "            #print(str(steeringValue) + \", \" + str(throttleValue))\n",
    "            median = draw_user_angle(steeringValue,throttleValue,median)\n",
    "\n",
    "            cv2.imshow(\"OUT\", median) \n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "    framecount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad7074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
