{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c3129e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9684/2427399221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pytorch Optimizer and Scheduler Related Task\n",
    "\"\"\"\n",
    "import math\n",
    "import logging\n",
    "import torch\n",
    "from torch import optim\n",
    "from config import cfg\n",
    "\n",
    "\n",
    "def get_optimizer(args, net):\n",
    "    \"\"\"\n",
    "    Decide Optimizer (Adam or SGD)\n",
    "    \"\"\"\n",
    "    param_groups = net.parameters()\n",
    "\n",
    "    if args.sgd:\n",
    "        optimizer = optim.SGD(param_groups,\n",
    "                              lr=args.lr,\n",
    "                              weight_decay=args.weight_decay,\n",
    "                              momentum=args.momentum,\n",
    "                              nesterov=False)\n",
    "    elif args.adam:\n",
    "        amsgrad = False\n",
    "        if args.amsgrad:\n",
    "            amsgrad = True\n",
    "        optimizer = optim.Adam(param_groups,\n",
    "                               lr=args.lr,\n",
    "                               weight_decay=args.weight_decay,\n",
    "                               amsgrad=amsgrad\n",
    "                               )\n",
    "    else:\n",
    "        raise ValueError('Not a valid optimizer')\n",
    "\n",
    "    if args.lr_schedule == 'scl-poly':\n",
    "        if cfg.REDUCE_BORDER_EPOCH == -1:\n",
    "            raise ValueError('ERROR Cannot Do Scale Poly')\n",
    "\n",
    "        rescale_thresh = cfg.REDUCE_BORDER_EPOCH\n",
    "        scale_value = args.rescale\n",
    "        lambda1 = lambda epoch: \\\n",
    "             math.pow(1 - epoch / args.max_epoch,\n",
    "                      args.poly_exp) if epoch < rescale_thresh else scale_value * math.pow(\n",
    "                          1 - (epoch - rescale_thresh) / (args.max_epoch - rescale_thresh),\n",
    "                          args.repoly)\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "    elif args.lr_schedule == 'poly':\n",
    "        lambda1 = lambda epoch: math.pow(1 - epoch / args.max_epoch, args.poly_exp)\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "    else:\n",
    "        raise ValueError('unknown lr schedule {}'.format(args.lr_schedule))\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def load_weights(net, optimizer, snapshot_file, restore_optimizer_bool=False):\n",
    "    \"\"\"\n",
    "    Load weights from snapshot file\n",
    "    \"\"\"\n",
    "    logging.info(\"Loading weights from model %s\", snapshot_file)\n",
    "    net, optimizer = restore_snapshot(net, optimizer, snapshot_file, restore_optimizer_bool)\n",
    "    return net, optimizer\n",
    "\n",
    "\n",
    "def restore_snapshot(net, optimizer, snapshot, restore_optimizer_bool):\n",
    "    \"\"\"\n",
    "    Restore weights and optimizer (if needed ) for resuming job.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(snapshot, map_location=torch.device('cpu'))\n",
    "    logging.info(\"Checkpoint Load Compelete\")\n",
    "    if optimizer is not None and 'optimizer' in checkpoint and restore_optimizer_bool:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    if 'state_dict' in checkpoint:\n",
    "        net = forgiving_state_restore(net, checkpoint['state_dict'])\n",
    "    else:\n",
    "        net = forgiving_state_restore(net, checkpoint)\n",
    "\n",
    "    return net, optimizer\n",
    "\n",
    "\n",
    "def forgiving_state_restore(net, loaded_dict):\n",
    "    \"\"\"\n",
    "    Handle partial loading when some tensors don't match up in size.\n",
    "    Because we want to use models that were trained off a different\n",
    "    number of classes.\n",
    "    \"\"\"\n",
    "    net_state_dict = net.state_dict()\n",
    "    new_loaded_dict = {}\n",
    "    for k in net_state_dict:\n",
    "        if k in loaded_dict and net_state_dict[k].size() == loaded_dict[k].size():\n",
    "            new_loaded_dict[k] = loaded_dict[k]\n",
    "        else:\n",
    "            logging.info(\"Skipped loading parameter %s\", k)\n",
    "    net_state_dict.update(new_loaded_dict)\n",
    "    net.load_state_dict(net_state_dict)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873718d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a320abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
